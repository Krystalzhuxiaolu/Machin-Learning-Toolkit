{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5abf3f60dc254cd656abb480d766db2d60a64423ce92680f144b473b08e2803f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Types of NLP： \n",
    "### 1. IF/ELSE RULES(CHATBOT)\n",
    "### 2. Audio Frequency components analysis (speech recognition)\n",
    "### 3. Bag of words model (classification)\n",
    "### 4. CNN for text recognition (classification)\n",
    "### 5. Seq2Seq (many appplications)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Importing the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "# Importing dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Restaurant_Reviews.tsv',delimiter='\\t', quoting=3) \n",
    "###delimiter default is , so now we specify \\t, also quoting=3 means that we are telling our model to ignore all double quote to avoid processing error"
   ]
  },
  {
   "source": [
    "# Cleaning the text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\XiaoluZhu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer ###applying stemming of the words(只看词根，避免了词态变化的带来的语义无法识别的情况)\n",
    "corpus = [] ###store all the cleaned text in corpus\n",
    "for i in range(0, 1000):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i]) ###sub function can replace anything in the string with anything you want, so here we want to delete puncutations(anything not a letter), so we replace the punctuation by spaces, means not all lower and upper letters a-z will be replaced\n",
    "  review = review.lower() ####to return all into lower letters\n",
    "  review = review.split() ###split the different elements of the review into different words\n",
    "  ps = PorterStemmer() ###create an object of PorterStemmer() and then apply this object to the data that we want \n",
    "  all_stopwords = stopwords.words('english')\n",
    "  all_stopwords.remove('not')\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)] ###if the words are not in the stopwords then we will consider since all the stopwords give us no hint of sentiments\n",
    "  review = ' '.join(review) ###the previous step returns all the single words after stemming and now you will have to put them all together, \" \".join means you will put a space between the words\n",
    "  corpus.append(review)"
   ]
  },
  {
   "source": [
    "# Creating bag of words model\n",
    "## Tokenization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)#1500 most frequent words\n",
    "X = cv.fit_transform(corpus).toarray() ###fit the corpus in X, put all the words in cols. the matrix has to be a 2D array\n",
    "y = dataset.iloc[:,-1].values ##last col of the dataset"
   ]
  },
  {
   "source": [
    "# Splitting the dataset into training and testing set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "source": [
    "# Training the Naive Bayes model on the trianing set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "# Predicting the test set results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 0]\n [1 0]\n [1 0]\n [0 0]\n [0 0]\n [1 0]\n [1 1]\n [1 0]\n [1 0]\n [1 1]\n [1 1]\n [1 1]\n [1 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 1]\n [1 1]\n [1 0]\n [1 0]\n [0 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [1 0]\n [0 0]\n [1 0]\n [1 1]\n [1 1]\n [1 0]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 0]\n [1 0]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 0]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [1 1]\n [1 0]\n [0 0]\n [1 0]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [1 0]\n [1 1]\n [0 1]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 0]\n [0 0]\n [1 1]\n [1 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [1 0]\n [1 1]\n [1 0]\n [1 1]\n [1 1]\n [1 0]\n [0 1]\n [1 1]\n [1 1]\n [1 0]\n [0 1]\n [1 0]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [0 1]\n [1 1]\n [0 0]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [1 1]\n [1 0]\n [0 0]\n [0 0]\n [1 1]\n [1 0]\n [0 0]\n [1 1]\n [1 0]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 0]\n [0 1]\n [1 1]\n [1 1]\n [0 0]\n [1 0]\n [0 0]\n [1 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 1]\n [1 1]\n [1 1]\n [1 0]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 0]\n [1 0]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [1 0]\n [0 0]\n [0 0]\n [0 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [1 0]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [1 0]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 0]\n [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "source": [
    "# Evaluating your performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[55 42]\n [12 91]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Predicting whether a single review is positive or negative "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "new_review = 'I dislike this restaurant so much'\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower()\n",
    "new_review = new_review.split()\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = ' '.join(new_review)\n",
    "new_corpus = [new_review]\n",
    "new_X_test = cv.transform(new_corpus).toarray()\n",
    "new_y_pred = classifier.predict(new_X_test)\n",
    "print(new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}